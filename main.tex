\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{booktabs} % For better table rules
\usepackage{longtable} % For tables spanning multiple pages if necessary
\usepackage{float}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}

\title{Programming Problem 1}
\author{}
\date{November 2024}

\begin{document}

\maketitle

\section*{Problem Description}
We are dealing with the Minimum Weighted Crossings with Constraints Problem (MWCCP), which is a generalization of the Minimum Crossings Problem.
The objective function to be minimized:
\[
f(\pi) = \sum_{(u, v) \in E} \sum_{\substack{(u', v') \in E \\ u < u'}} 
(w_{u,v} + w_{u', v'}) \cdot \delta_{\pi}((u, v), (u', v'))
\]
where
\[
\delta_{\pi}((u, v), (u', v')) = 
\begin{cases} 
1 & \text{if } \text{pos}_{\pi}(v) > \text{pos}_{\pi}(v'), \\ 
0 & \text{otherwise.} 
\end{cases}
\]

\section*{Question 1}
Application: Railway Scheduling and Track Layout
\begin{itemize}
    \item Nodes in \(U\) could represent fixed train stations along a route, where trains must stop in a specific order
    \item Nodes in \(V\) could represent trains/train routes to be scheduled within the network
    \item Weighted edges would indicate the relationship between trains/train routes and tracks, with higher weights representing either higher traffic, longer distance, lower importance in terms of scheduling (in case of for example local vs. high speed train)
    \item Constraints in C would enforce rules like the fact that certain trains need to arrive before others or that trains using the same tracks do not overlap.
\end{itemize}

The objective then would be to arrange the schedules in V to minimize the crossings of tracks while satisfying all constraints in C. This would lead to improved security and efficiency as minimizing track crossings would reduce the likelihood of collisions or delays due to track conflicts.


\section*{Q2: Deterministic Construction Heuristic}

\subsection*{Algorithm Description}

A meaningful deterministic construction heuristic could be one based on a greedy approach:
\begin{itemize}
    \item Initialize an empty ordered permutation list $\pi$ for nodes in $V$
    \item Compute for each node in $V$ the number of constraints that require other nodes to come before it
    \item Create a list of candidates with nodes in $V$ that have no predecessors
    \item For every node in the candidates and until $V$ is empty
    \begin{itemize}
        \item calculate the total weight of edges connecting it to U
        \item select the node with the lowest total edge weight to nodes in $U$ and append it to the final permutation list $\pi$
        \item  update the in-degree of nodes that had this as a constraint reducing it by $1$
        \item if the in-degree of any node in $V$ reaches zero add it to the candidates
        
    \end{itemize}
\end{itemize}

\subsection*{Components}

\paragraph{Input Structure:}
\begin{itemize}
    \item The graph structure includes nodes \( U \) and \( V \), edges \( E \), and edge weights.
    \item \textbf{Constraints:} A mapping of precedence relationships such that if \( v_1 \to v_2 \), node \( v_1 \) must precede \( v_2 \) in the final ordering.
\end{itemize}

\paragraph{Node Weight Precomputation:}
To imporve efficiency, the algorithm precomputes the sum of incoming edge weights for each node in \( V \). This will serve as a heuristic for selecting the "best" candidate node during construction.

\paragraph{Initialization of Candidates:}
Nodes with an in-degree of zero (i.e., no unfulfilled constraints) are initialized as candidates for the ordering. These nodes are stored in a \texttt{deque} for efficient addition and removal.

\paragraph{Greedy Node Selection:}
At each step, the algorithm selects the node from the candidates with the smallest total incoming edge weight. This \textbf{problem-specific heuristic} aims to minimize high-cost crossings early in the construction process.

\paragraph{Update Mechanism:}
Once a node is selected, it is removed from the candidate set and appended to the ordering \( \pi \). The algorithm then reduces the in-degrees of its dependent nodes. If a dependent node's in-degree becomes zero, it is added to the candidate set.

\paragraph{Solution Verification:}
After constructing \( \pi \), the algorithm verifies:
\begin{itemize}
    \item All nodes in \( V \) are included exactly once.
    \item All precedence constraints are respected
\end{itemize}

\subsection*{Adaptations}
\begin{itemize}
    \item \textbf{Problem-Specific Heuristic:} The algorithm prioritizes nodes with lower edge weights to reduce crossings early in the construction.
    \item \textbf{Constraint Management:} Using in-degrees to dynamically track feasible candidates ensures constraints are respected throughout the process.
    \item \textbf{Solution Verification:} A final verification step guarantees correctness.
\end{itemize}

\subsection*{Results}
The quality of the solution given by our Deterministic Construction Heuristic is competitive as it is visible from the competition results, while being very fast. Below we report some performance metrics for the different test instance sizes.

\subsubsection*{Small}
\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Instance}         & \textbf{Time (s)} & \textbf{Cost} \\ \hline
inst\_50\_4\_00002 & 0.000799 & 31619.0 \\ \hline
inst\_50\_4\_00004 & 0.000259 & 8582.0  \\ \hline
inst\_50\_4\_00007 & 0.000155 & 3463.0  \\ \hline
inst\_50\_4\_00005 & 0.000122 & 6034.0  \\ \hline
inst\_50\_4\_00009 & 0.000128 & 2633.0  \\ \hline
inst\_50\_4\_00003 & 0.000148 & 15511.0 \\ \hline
inst\_50\_4\_00006 & 0.000166 & 4883.0  \\ \hline
inst\_50\_4\_00010 & 0.000119 & 1658.0  \\ \hline
inst\_50\_4\_00001 & 0.000279 & 84883.0 \\ \hline
inst\_50\_4\_00008 & 0.000426 & 3005.0  \\ \hline
\end{tabular}
\caption{Results for Small instances (Avg. time = 0.000557 s)}
\end{table}

\subsubsection*{Medium}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Instance}         & \textbf{Time (s)} & \textbf{Cost} \\ \hline
inst\_200\_20\_00008 & 0.000852 & 709644.0   \\ \hline
inst\_200\_20\_00001 & 0.001486 & 23033165.0 \\ \hline
inst\_200\_20\_00009 & 0.000805 & 547596.0   \\ \hline
inst\_200\_20\_00010 & 0.000881 & 461537.0   \\ \hline
inst\_200\_20\_00006 & 0.000879 & 1217519.0  \\ \hline
inst\_200\_20\_00004 & 0.000938 & 2551528.0  \\ \hline
inst\_200\_20\_00005 & 0.001722 & 1627621.0  \\ \hline
inst\_200\_20\_00003 & 0.001898 & 4361007.0  \\ \hline
inst\_200\_20\_00007 & 0.001528 & 908103.0   \\ \hline
inst\_200\_20\_00002 & 0.002308 & 8390614.0  \\ \hline
\end{tabular}
\caption{Results for Medium instances}
\end{table}

\subsubsection*{Medium-Large}
\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Instance}         & \textbf{Time (s)} & \textbf{Cost} \\ \hline
inst\_500\_40\_00001 & 0.012615 & 40802322.0  \\ \hline
inst\_500\_40\_00010 & 0.021615 & 247294126.0 \\ \hline
inst\_500\_40\_00019 & 0.015958 & 532473137.0 \\ \hline
inst\_500\_40\_00013 & 0.012978 & 334007118.0 \\ \hline
inst\_500\_40\_00007 & 0.016719 & 168022855.0 \\ \hline
inst\_500\_40\_00016 & 0.015179 & 437097158.0 \\ \hline
inst\_500\_40\_00004 & 0.009197 & 94454966.0  \\ \hline
\end{tabular}
\caption{Results for Medium-Large instances}
\end{table}


\subsubsection*{Large}
\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Instance}         & \textbf{Time (s)} & \textbf{Cost} \\ \hline
inst\_1000\_60\_00005 & 0.032712 & 1065285851.0  \\ \hline
inst\_1000\_60\_00002 & 0.066785 & 5340801153.0  \\ \hline
inst\_1000\_60\_00004 & 0.039137 & 1614552426.0  \\ \hline
inst\_1000\_60\_00001 & 0.136459 & 15151194763.0 \\ \hline
inst\_1000\_60\_00003 & 0.045279 & 2701197831.0  \\ \hline
inst\_1000\_60\_00007 & 0.027055 & 569249713.0   \\ \hline
inst\_1000\_60\_00006 & 0.030169 & 767270792.0   \\ \hline
inst\_1000\_60\_00008 & 0.039558 & 451262171.0   \\ \hline
inst\_1000\_60\_00009 & 0.027395 & 358976591.0   \\ \hline
inst\_1000\_60\_00010 & 0.031849 & 293146116.0   \\ \hline
\end{tabular}
\caption{Results for Large instances}
\end{table}



\section*{Q3: Randomized Construction Heuristic}
The randomized heuristic could roughly follow the same process as the deterministic one, but then, when choosing the node in $V$ to add to the final permutation list $\pi$, instead of always choosing the one that has a minimum weighted sum of edges to $U$, pick one randomly, with a probability inversely proportional to this sum.
In particular we will use a Boltzmann Distribution to balance randomness and greedy choice. 

\paragraph{Probability Calculation:}
Compute the probabilities for selecting a node from the current candidates using a Boltzmann distribution. More in details:
\begin{itemize}
    \item Calculate scores for all candidate nodes
    \item Normalize the scores to avoid overflow
    \item Compute the probabilities using: 
    \(p_i = \frac{\exp{(-\frac{s_i}{\alpha})}}{\sum_j \exp{(-\frac{s_j}{\alpha})}}\), where \(s_i\) is the normalized score for node \( i\).
\end{itemize}
The parameter $\alpha$ controls randomness: a smaller $\alpha$ increases randomness, while a larger value value favors greediness.
In this way, nodes with higher cost/score have lower probability to be selected.

\paragraph{Single Solution Construction:}
The steps are very similar to the deterministic construction heuristic.
\begin{itemize}
    \item Start with all nodes having in-degree zero.
    \item Randomly select a node from candidates using the probabilities.
    \item Add the node to the ordering, remove it from the candidates, and update in-degrees of connected nodes.
    \item Repeat until all nodes are ordered.
\end{itemize}


\paragraph{Multiple Iterations:}
We also add the possibility to run the single-solution construction multiple times to improve the results and get lower variance. In particular the steps are:
\begin{itemize}
    \item Repeat the construction process $num_iterations$ times.
    \item Evaluate the cost of each solution.
    \item Keep the best solution found.
\end{itemize}


\subsection*{Results}
The results are computed using a single iteration and a parameter $\alpha = 0.6$.

\subsubsection*{Small}

\begin{table}[H]
\centering
\hspace*{-1.5cm}
\begin{tabular}{llllll}
\toprule
\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
\midrule
\texttt{inst\_50\_4\_00002} & 0.003626 & 30855.97 & 27857.00 & 32643.00 & 1050.59 \\
\texttt{inst\_50\_4\_00004} & 0.003219 & 9172.10  & 7928.00  & 10239.00 & 500.92  \\
\texttt{inst\_50\_4\_00007} & 0.001821 & 3578.43  & 2827.00  & 4096.00  & 288.79  \\
\texttt{inst\_50\_4\_00005} & 0.002545 & 5569.87  & 4853.00  & 6219.00  & 351.73  \\
\texttt{inst\_50\_4\_00009} & 0.002607 & 2492.43  & 2091.00  & 2784.00  & 191.61  \\
\texttt{inst\_50\_4\_00003} & 0.003283 & 15485.43 & 13478.00 & 16528.00 & 722.92  \\
\texttt{inst\_50\_4\_00006} & 0.002801 & 4650.20  & 4092.00  & 5232.00  & 290.86  \\
\texttt{inst\_50\_4\_00010} & 0.001948 & 1620.17  & 1355.00  & 1975.00  & 131.56  \\
\texttt{inst\_50\_4\_00001} & 0.003809 & 84930.00 & 80297.00 & 88682.00 & 2078.92 \\
\texttt{inst\_50\_4\_00008} & 0.001744 & 2915.70  & 2136.00  & 3360.00  & 273.16  \\
\midrule
\textbf{Summary Statistics} & \textbf{0.002740} & \textbf{16127.03} & - & - & - \\
\bottomrule
\end{tabular}
\label{tab:performance_metrics_randomized}
\end{table}

\subsubsection*{Medium}
\begin{table}[H]
\centering
\hspace*{-1.5cm}
\begin{tabular}{llllll}
\toprule
\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
\midrule
\texttt{inst\_200\_20\_00010} & 0.015873 & 456531.27  & 445306.00   & 470534.00   & 7330.93   \\
\texttt{inst\_200\_20\_00009} & 0.015896 & 543713.67  & 521951.00   & 568060.00   & 11855.02  \\
\texttt{inst\_200\_20\_00006} & 0.019273 & 1207213.20 & 1166898.00  & 1238370.00  & 18112.10  \\
\texttt{inst\_200\_20\_00003} & 0.029675 & 4327121.80 & 4250721.00  & 4399702.00  & 42645.01  \\
\texttt{inst\_200\_20\_00002} & 0.043474 & 8361784.40 & 8195701.00  & 8506730.00  & 82622.20  \\
\texttt{inst\_200\_20\_00004} & 0.037687 & 2551007.27 & 2490237.00  & 2615850.00  & 30495.64  \\
\texttt{inst\_200\_20\_00007} & 0.030310 & 904974.73  & 881311.00   & 939154.00   & 15387.23  \\
\texttt{inst\_200\_20\_00001} & 0.061063 & 23195717.50 & 22931228.00 & 23599133.00 & 162599.73 \\
\texttt{inst\_200\_20\_00008} & 0.016568 & 713576.87  & 679658.00   & 739042.00   & 15210.27  \\
\texttt{inst\_200\_20\_00005} & 0.021958 & 1613500.70 & 1561975.00  & 1656848.00  & 23931.89  \\
\midrule
\textbf{Summary Statistics} & \textbf{0.029178} & \textbf{4387514.14} & - & - & - \\
\bottomrule
\end{tabular}
\label{tab:medium_performance_metrics_randomized}
\end{table}

\subsubsection*{Medium-Large}
\begin{table}[H]
\centering
\hspace*{-2cm}
\begin{tabular}{llllll}
\toprule
\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
\midrule
\texttt{inst\_500\_40\_00001} & 0.177799 & 41306375.60  & 40921403.00  & 41835187.00  & 249191.77  \\
\texttt{inst\_500\_40\_00010} & 0.396382 & 248177497.60 & 246238999.00 & 249837668.00 & 920296.47  \\
\texttt{inst\_500\_40\_00019} & 0.603033 & 533048783.97 & 528410832.00 & 536610229.00 & 2055959.77 \\
\texttt{inst\_500\_40\_00013} & 0.450295 & 334334851.00 & 332129824.00 & 336682608.00 & 1098089.99 \\
\texttt{inst\_500\_40\_00007} & 0.342089 & 167237198.67 & 165989443.00 & 168598596.00 & 719070.85  \\
\texttt{inst\_500\_40\_00016} & 0.535916 & 436747201.67 & 433165807.00 & 439570395.00 & 1724318.23 \\
\texttt{inst\_500\_40\_00004} & 0.261199 & 94402713.37  & 92471418.00  & 95619239.00  & 828955.05  \\
\midrule
\textbf{Summary Statistics} & \textbf{0.395245} & \textbf{265036374.55} & - & - & - \\
\bottomrule
\end{tabular}
\label{tab:medium_large_performance_metrics_randomized}
\end{table}

\subsubsection*{Large}

\begin{table}[H]
\centering
\hspace*{-2cm}
\begin{tabular}{llllll}
\toprule
\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
\midrule
\texttt{inst\_1000\_60\_00005} & 1.940377 & 1067764674.70  & 1060835463.00  & 1075136067.00  & 3443214.33  \\
\texttt{inst\_1000\_60\_00002} & 5.258952 & 5339427349.17  & 5316206983.00  & 5358163297.00  & 9952612.22  \\
\texttt{inst\_1000\_60\_00004} & 2.576052 & 1618919043.03  & 1604354503.00  & 1629522719.00  & 5881501.28  \\
\texttt{inst\_1000\_60\_00001} & 9.653994 & 15145125818.07 & 15119309857.00 & 15174139010.00 & 15114903.03 \\
\texttt{inst\_1000\_60\_00003} & 3.577870 & 2710183271.13  & 2698638355.00  & 2723048821.00  & 6434495.93  \\
\texttt{inst\_1000\_60\_00007} & 1.234546 & 568833774.80   & 564743332.00   & 571513933.00   & 1777165.09  \\
\texttt{inst\_1000\_60\_00006} & 1.506673 & 771255574.13   & 765180918.00   & 777979955.00   & 3043546.59  \\
\texttt{inst\_1000\_60\_00008} & 1.053052 & 450177254.10   & 446090463.00   & 455253372.00   & 2137433.51  \\
\texttt{inst\_1000\_60\_00009} & 0.886946 & 357376938.03   & 354133103.00   & 359544918.00   & 1668191.08  \\
\texttt{inst\_1000\_60\_00010} & 0.773536 & 294319001.80   & 291894077.00   & 297714026.00   & 1198184.49  \\
\midrule
\textbf{Summary Statistics} & \textbf{2.846200} & \textbf{2832338269.90} & - & - & - \\
\bottomrule
\end{tabular}
\label{tab:large_performance_metrics_randomized}
\end{table}

\section*{Q4: Local Search}
We developed a framework for basic local search able to deal with different neighborhood structures and different step functions.

\subsection*{Local Search Procedure}

The local search algorithm follows these steps:

\begin{enumerate}
    \item \textbf{Initialization:} 
    \begin{itemize}
        \item Start with an initial solution \( \text{current\_solution} \).
        \item Set key parameters:
        \begin{itemize}
            \item Maximum number of iterations (\( \text{max\_iter} \)).
            \item Maximum plateau (\( \text{max\_plateau} \)), i.e., consecutive iterations without improvement before termination.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Neighborhood Generation:}
    \begin{itemize}
        \item Generate a set of neighboring solutions using a selected neighborhood structure:
        \begin{itemize}
            \item Swap
            \item Insert
            \item Reverse
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Solution Selection:}
    \begin{itemize}
        \item Select the next solution based on the chosen step function. Three different step functions are allowed:
        \begin{itemize}
            \item \textbf{Best Improvement:} Explore all neighbors and select the one with the lowest cost.
            \item \textbf{First Improvement:} Select the first neighbor that improves the current cost.
            \item \textbf{Random:} Select a random neighbor from the set of valid neighbors.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Iteration:}
    \begin{itemize}
        \item Evaluate the cost of the selected solution using the cost function \( f(\text{s}) \).
        \item Update the best solution and plateau counter:
        \begin{itemize}
            \item If the selected solution improves the best cost, update \( \text{best\_solution} \) and reset the plateau counter.
            \item Otherwise, increment the plateau counter.
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Termination:}
    \begin{itemize}
        \item Stop the search when either:
        \begin{itemize}
            \item The maximum number of iterations (\( \text{max\_iter} \)) is reached.
            \item The plateau counter exceeds \( \text{max\_plateau} \).
        \end{itemize}
    \end{itemize}
    
    \item \textbf{Statistics:}
    \begin{itemize}
        \item Record statistics such as improvement history, runtime, and local optima encountered.
    \end{itemize}
\end{enumerate}


\section*{Q5: Neighborhood Structures}
\subsubsection*{1. Swap Neighborhood}
\textbf{Description:} Neighbors are generated by swapping adjacent nodes in the solution.

\noindent \textbf{Procedure:}  For all adjacent node pairs, swap their positions if the swap respects constraints and add the resulting solution to the set of neighbors if it is valid.

\noindent \textbf{Purpose:} This structure performs small modifications to find similar solutions to the current one that have better cost.

\subsubsection*{2. Insert Neighborhood}
\textbf{Description:} Neighbors are generated by removing a node from its position and inserting it at a different position.

\noindent \textbf{Process:} For all pairs of positions \( (i, j) \), remove the node at position \( i \) and insert it at \( j \) and add the resulting solution to the set of neighbors if it is valid.

\noindent \textbf{Purpose:} Allows larger modifications of the solution, exploring solutions with higher order changes.

\subsubsection*{3. Reverse Neighborhood}
\textbf{Description:} Neighbors are generated by reversing the order of a subsequence of nodes.

\noindent \textbf{Process:} For all subsequences \( (i, j) \) where \( j > i + 1 \), reverse the order of nodes between \( i \) and \( j \) and add the resulting solution to the set of neighbors if it is valid.

\noindent \textbf{Purpose:} Even higher order changes in the solution, in order to escape local optima.


\section*{Q6: Variable Neighborhood Descent (VND)}
\subsection*{Algorithm and Adaptations}
The algorithm consists of a simple implementation of VND with support for multiple neighborhoods and step functions. The parameters that can be changed for the algorithm are: \textbf{maximum number of iterations}, \textbf{step function}, \textbf{objective function} (function for calculating the score), \textbf{neighborhood order}. The algorithm also tracks statistics.

\paragraph{Neighborhoods:}
VDN as well as other algorithms support 3 neighborhoods. All neighborhoods are implemented as generator functions which can speed up the computation if not all elements of the neighborhood are needed. These are the supported neighborhoods:
\begin{itemize}
	\item \textbf{Swap neighborhood:} The neighborhood of all solutions which can be obtained by swapping the positions of 2 elements.
	\item \textbf{Insert neighborhood:} The neighborhood of all solutions which can be obtained by removing an element and inserting it in another place in the solution.
	\item \textbf{Reverse neighborhood:} The neighborhood of all solutions which can be obtained by reversing an interval of the solution.
\end{itemize}

\paragraph{Step functions:}
VDN as well as other algorithms support the following step functions:
\begin{itemize}
	\item \textbf{Best Improvement:} The next solution is chosen as the solution with the best cost in the neighborhood.
	\item \textbf{First Improvement:} The first encountered solution with a better cost then the current one is chosen.
	\item \textbf{Random:} A random solution from the neighborhood is chosen.
\end{itemize}
\subsection*{Performance Factors}
The performance of the algorithm is affected by the chosen parameters. The algorithm was tested with multiple combinations of parameters on the tuning instances and the following trends were seen:

\paragraph{Maximum iterations:} 
The maximum number of iteration is one of the most directly correlated paramaters. The maximum number of iteration has a linear correlation with the time taken, as more iterations there are, the slower will the execution be. For each instance there is also a limit which is also based on other parameters which stops the increase of the time taken.

\paragraph{Step function:}
The step function has a big influence on the solution. The \textit{Random} function is really fast, it doesn't give good solutions so it wasn'y used in the tests. While the \textit{Best Improvement} function gives the best result, the time taken to generate the whole neighborhood on larger instances is too large and is beaten in speed and solution cost by the \textit{First Improvement} with a 10 times larger maximum iterations, so the latter was used in most of the tests.

\paragraph{Objective function:}
There are multiple implementations of the cost functions and the 2 most notable are the \textit{cost\_function\_bit} which uses a Fenwick tree to efficiently calculate the cost ($O(E \log E)$, where $E$ is the number of edges) and the cost function which uses delta evaluation using pre calculated prefix sums of weights for the nodes and using only the nodes that have changed ($O(E*diff)$, where $diff$ is the number of changed node). In most cases the second function was used as it performs better.

\paragraph{Neighborhood order:}
The order of the neighborhood functions also has a big influence on speed, and a lesser influence on cost. The \textit{Swap} neighborhood is the fastes but performs the worst, \textit{Reverse} neigbhborhood performs the second best in both aspects and the \textit{Insert} neigbhborhood is the slowest and give an almost negligeble cost improvement over the \textit{Reverse} neigbhborhood. For larger instances, the first neighborhood in the order must be the \textit{Swap} neighborhood as otherwise it would take too much time.


\subsection*{Performance}
The tests were ran on a Macbook Pro 16" M2 Pro. The VND algorithm is deterministic in these tests, and that is why the std dev was column  left out, the other columns were kept for appearance and to show that it was deterministic. All the test have been ran with the following parameters: 
\begin{itemize}
	\item \textbf{Max iterations:} 250
	\item \textbf{Neighborhood order:} Swap, Reverse, Insert
	\item \textbf{Step function:} First Improvement
	\item \textbf{Times ran:} 10 for all instances except large which was 1 (only the time differs between runs)
\end{itemize}

\subsection*{Small}

\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost}  \\
		\midrule
		\texttt{inst\_50\_4\_00002} & 0.3237 & 23982.0 & 23982.0 & 23982.0 \\ 
		\texttt{inst\_50\_4\_00004} & 0.3877 & 6534.0  & 6534.0  & 6534.0  \\ 
		\texttt{inst\_50\_4\_00007} & 0.2896 & 2054.0  & 2054.0  & 2054.0  \\ 
		\texttt{inst\_50\_4\_00005} & 0.3616 & 3580.0  & 3580.0  & 3580.0  \\ 
		\texttt{inst\_50\_4\_00009} & 0.9380 & 1303.0  & 1303.0  & 1303.0  \\ 
		\texttt{inst\_50\_4\_00003} & 0.4459 & 12278.0 & 12278.0 & 12278.0 \\ 
		\texttt{inst\_50\_4\_00006} & 0.2992 & 2959.0  & 2959.0  & 2959.0  \\ 
		\texttt{inst\_50\_4\_00010} & 0.2575 & 857.0   & 857.0   & 857.0   \\ 
		\texttt{inst\_50\_4\_00001} & 1.0881 & 74406.0 & 74406.0 & 74406.0 \\ 
		\texttt{inst\_50\_4\_00008} & 0.1650 & 1405.0  & 1405.0  & 1405.0  \\ 
		\midrule
		\textbf{Summary Statistics} & \textbf{0.4554} & \textbf{12935.8} & - & - \\
		\bottomrule
	\end{tabular}
	\label{tab:performance_metrics_small_vnd}
\end{table}


\subsection*{Medium}
\begin{table}[H]
 	 \centering 
 	 \begin{tabular}{lrrrrr} 
 	 	\toprule 
 	 	\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} \\ 
 	 	\midrule 
 	 	\texttt{inst\_200\_20\_00010} & 0.9009 & 454212.00 & 454212.00 & 454212.00  \\ \texttt{inst\_200\_20\_00009} & 0.6965 & 539627.00 & 539627.00 & 539627.00 \\ \texttt{inst\_200\_20\_00008} & 0.9636 & 700167.00 & 700167.00 & 700167.00 \\  \texttt{inst\_200\_20\_00007} & 1.2543 & 892949.00 & 892949.00 & 892949.00 \\  \texttt{inst\_200\_20\_00006} & 1.1160 & 1198988.00 & 1198988.00 & 1198988.00 \\  \texttt{inst\_200\_20\_00005} & 1.6312 & 1608128.00 & 1608128.00 & 1608128.00 \\  \texttt{inst\_200\_20\_00004} & 2.0465 & 2524537.00 & 2524537.00 & 2524537.00 \\  \texttt{inst\_200\_20\_00003} & 2.0466 & 4308610.00 & 4308610.00 & 4308610.00 \\  \texttt{inst\_200\_20\_00002} & 3.8624 & 8306145.00 & 8306145.00 & 8306145.00 \\  \texttt{inst\_200\_20\_00001} & 5.4359 & 22865269.00 & 22865269.00 & 22865269.00 \\ 
 	 	\midrule 
 	 	\textbf{Summary Statistics} & \textbf{1.9953} & \textbf{4339863.2} & - & - \\ 
 	 	\bottomrule
 	  \end{tabular}
 	  \label{tab:performance_metrics_medium_vnd}
\end{table}

\subsection*{Medium-Large}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} \\
		\midrule
		\texttt{inst\_500\_40\_00001} & 7.713967 & 40746020.00  & 40746020.00  & 40746020.00  \\
		\texttt{inst\_500\_40\_00010} & 19.30043 & 247021962.00 & 247021962.00 & 247021962.00  \\
		\texttt{inst\_500\_40\_00019} & 26.84756 & 532160524.00 & 532160524.00 & 532160524.00 \\
		\texttt{inst\_500\_40\_00013} & 28.13974 & 333729516.00 & 333729516.00 & 333729516.00 \\
		\texttt{inst\_500\_40\_00007} & 14.91125 & 167816702.00 & 167816702.00 & 167816702.00  \\
		\texttt{inst\_500\_40\_00016} & 25.80133 & 436785606.00 & 436785606.00 & 436785606.00  \\
		\texttt{inst\_500\_40\_00004} & 11.56564 & 94332575.00  & 94332575.00  & 94332575.00  \\
		\midrule
		\textbf{Summary Statistics} & \textbf{19.1828} & \textbf{264656129.29} & - & -  \\
		\bottomrule
	\end{tabular}
	\label{tab:medium_large_performance_metrics_vnd}
\end{table}

\subsection*{Large}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} \\
		\midrule
		\texttt{inst\_1000\_60\_00005} & 48.58142 & 1065061908.00  & 1065061908.00  & 1065061908.00   \\
		\texttt{inst\_1000\_60\_00002} & 126.88115 & 5340070725.00  & 5340070725.00  & 5340070725.00   \\
		\texttt{inst\_1000\_60\_00004} & 47.21685 & 1614136455.00  & 1614136455.00  & 1614136455.00 \\
		\texttt{inst\_1000\_60\_00001} & 275.15735 & 15149609242.00 & 15149609242.00 & 15149609242.00  \\
		\texttt{inst\_1000\_60\_00003} & 98.87615 & 2700741000.00  & 2700741000.00  & 2700741000.00 \\
		\texttt{inst\_1000\_60\_00007} & 32.09443 & 569122169.00   & 569122169.00   & 569122169.00 \\
		\texttt{inst\_1000\_60\_00006} & 41.20420 & 767104436.00   & 767104436.00   & 767104436.00 \\
		\texttt{inst\_1000\_60\_00008} & 34.37336 & 451129061.00   & 451129061.00   & 451129061.00  \\
		\texttt{inst\_1000\_60\_00009} & 23.47634 & 358888563.00   & 358888563.00   & 358888563.00 \\
		\texttt{inst\_1000\_60\_00010} & 23.55307 & 293069393.00   & 293069393.00   & 293069393.00 \\
		\midrule
		\textbf{Summary Statistics} & \textbf{2830893295.20} & \textbf{75.14143} & - & - & - \\
		\bottomrule
	\end{tabular}
	\label{tab:large_performance_metrics_vnd}
\end{table}

\section*{Greedy Randomized Adaptive Search Procedure(GRASP)}
\subsection*{Algorithm and Adaptations}
In this implementation GRASP uses greedy randomised construction and the VND implementation for local search.  The greedy randomised contruction uses a combination of a greedy approach and randomness to get a solution after which it is refined using VND. The algorithm itself has these parameters that can influence the result: \textbf{max iterations}, \textbf{alpha} (How random is the algorithm), \textbf{neighborhood structures}, \textbf{step function}, \textbf{vnd max iterations}.

\paragraph{Alpha:}
The alpha parameter influences the randomness of the algorithm. It can have a value of 0 to 1 where 0 is purely greedy while 1 being completely random.

\subsection*{Performance}
The tests were ran on a Macbook Pro 16" M2 Pro. All the test have been ran with the following parameters: 
\begin{itemize}
	\item \textbf{Max iterations:} 
	\item \textbf{Neighborhood structures:} Swap, Reverse, Insert
	\item \textbf{Step function:} First Improvement
	\item \textbf{Alpha:} 
	\item \textbf{Times ran:} 
\end{itemize}

\subsection*{Small}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
		\midrule
		\texttt{inst\_50\_4\_00002} & 0.104611 & 24933.6 & 23982.0 & 27000.0 & 1103.55 \\ 
		\texttt{inst\_50\_4\_00004} & 0.021516 & 7460.2  & 6942.0  & 8067.0  & 390.92 \\ 
		\texttt{inst\_50\_4\_00007} & 0.037690 & 2345.4  & 2099.0  & 2652.0  & 219.31 \\ 
		\texttt{inst\_50\_4\_00005} & 0.041543 & 3898.0  & 3691.0  & 4188.0  & 207.01 \\ 
		\texttt{inst\_50\_4\_00009} & 0.037616 & 1533.2  & 1385.0  & 1802.0  & 152.88 \\ 
		\texttt{inst\_50\_4\_00003} & 0.045658 & 13267.2 & 12821.0 & 13560.0 & 266.90 \\ 
		\texttt{inst\_50\_4\_00006} & 0.038624 & 3226.6  & 3102.0  & 3336.0  & 91.00  \\ 
		\texttt{inst\_50\_4\_00010} & 0.033737 & 1081.2  & 899.0   & 1624.0  & 276.06 \\ 
		\texttt{inst\_50\_4\_00001} & 0.088662 & 77435.4 & 74900.0 & 80848.0 & 2078.90 \\ 
		\texttt{inst\_50\_4\_00008} & 0.034032 & 1581.2  & 1470.0  & 1762.0  & 99.07  \\ 
		\midrule
		\textbf{Summary Statistics} & \textbf{0.0484} & \textbf{13676.2} & - & - & - \\
		\bottomrule
	\end{tabular}
	\label{tab:performance_metrics_small_grasp}
\end{table}


\subsection*{Medium}
\begin{table}[H]
	\centering 
	\begin{tabular}{lrrrrr} 
		\toprule 
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
		\midrule 
		\texttt{inst\_200\_20\_00010} & 3.9998 & 426375.8 & 405780.0 & 449650.0 & 14684.48 \\ 
		\texttt{inst\_200\_20\_00009} & 0.8330 & 525452.0 & 515265.0 & 537782.0 & 7186.38 \\ 
		\texttt{inst\_200\_20\_00008} & 0.6071 & 642463.2 & 627365.0 & 663653.0 & 11891.28 \\  
		\texttt{inst\_200\_20\_00007} & 1.4284 & 874448.0 & 862636.0 & 891027.0 & 12383.73 \\  
		\texttt{inst\_200\_20\_00006} & 7.3983 & 1140584.6 & 1106569.0 & 1185142.0 & 28084.81 \\  
		\texttt{inst\_200\_20\_00005} & 0.5746 & 1556662.8 & 1541167.0 & 1594146.0 & 19848.85 \\  
		\texttt{inst\_200\_20\_00004} & 0.9376 & 2408182.2 & 2344128.0 & 2474783.0 & 45656.43 \\  
		\texttt{inst\_200\_20\_00003} & 1.9283 & 4140673.8 & 4030008.0 & 4253200.0 & 71730.50 \\  
		\texttt{inst\_200\_20\_00002} & 18.5041 & 8127653.6 & 7955555.0 & 8250767.0 & 138759.84 \\  
		\texttt{inst\_200\_20\_00001} & 12.6312 & 22693077.6 & 22309294.0 & 22906959.0 & 219015.22 \\ 
		\midrule 
		\textbf{Summary Statistics} & \textbf{4.9745} & \textbf{6843733.10} & - & - \\ 
		\bottomrule
	\end{tabular}
	\label{tab:performance_metrics_medium_grasp}
\end{table}


\subsection*{Medium-Large}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} \\
		\midrule
		\texttt{inst\_500\_40\_00001} & 81.91235 & 40161294.00  & 40109112.00  & 40208298.00 &  40657.71\\
		\texttt{inst\_500\_40\_00010} & 20.28370 & 244675374.66 & 244449482.00 & 245069841.00 &  279909.67\\
		\texttt{inst\_500\_40\_00019} & 15.30449 & 528918152.33 & 526096773.00 & 530461681.00 & 1997962.66\\
		\texttt{inst\_500\_40\_00013} & 41.27252 & 330123938.0.00 & 328263464.00 & 331348436.00 & 1268323.96 \\
		\texttt{inst\_500\_40\_00007} & 21.765949 & 164770693.00 & 163821323.00 & 165299551.00  & 672761.60\\
		\texttt{inst\_500\_40\_00016} & 21.713235 & 432797031.67 & 431431993.00 & 434524182.00  & 1288086.91 \\
		\texttt{inst\_500\_40\_00004} & 18.120888 & 93151443.33  & 92486709.00  & 94022108.00  & 643515.35 \\
		\midrule
		\textbf{Summary Statistics} & \textbf{0.395245} & \textbf{265036374.55} & - & -  \\
		\bottomrule
	\end{tabular}
	\label{tab:medium_large_performance_metrics_grasp}
\end{table}


\subsection*{Large}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
		\midrule
		\texttt{inst\_1000\_60\_00005} & 1.940377 & 1067764674.70  & 1060835463.00  & 1075136067.00  & 3443214.33  \\
		\texttt{inst\_1000\_60\_00002} & 5.258952 & 5339427349.17  & 5316206983.00  & 5358163297.00  & 9952612.22  \\
		\texttt{inst\_1000\_60\_00004} & 2.576052 & 1618919043.03  & 1604354503.00  & 1629522719.00  & 5881501.28  \\
		\texttt{inst\_1000\_60\_00001} & 9.653994 & 15145125818.07 & 15119309857.00 & 15174139010.00 & 15114903.03 \\
		\texttt{inst\_1000\_60\_00003} & 3.577870 & 2710183271.13  & 2698638355.00  & 2723048821.00  & 6434495.93  \\
		\texttt{inst\_1000\_60\_00007} & 1.234546 & 568833774.80   & 564743332.00   & 571513933.00   & 1777165.09  \\
		\texttt{inst\_1000\_60\_00006} & 1.506673 & 771255574.13   & 765180918.00   & 777979955.00   & 3043546.59  \\
		\texttt{inst\_1000\_60\_00008} & 1.053052 & 450177254.10   & 446090463.00   & 455253372.00   & 2137433.51  \\
		\texttt{inst\_1000\_60\_00009} & 0.886946 & 357376938.03   & 354133103.00   & 359544918.00   & 1668191.08  \\
		\texttt{inst\_1000\_60\_00010} & 0.773536 & 294319001.80   & 291894077.00   & 297714026.00   & 1198184.49  \\
		\midrule
		\textbf{Summary Statistics} & \textbf{} & \textbf{} & - & - & - \\
		\bottomrule
	\end{tabular}
	\label{tab:large_performance_metrics_grasp}
\end{table}


\section*{Q7: GRASP}

\section*{Q8: General Variable Neighborhood Search(GVNS)}
\subsection*{Algorithm and Adaptations}
GVNS combines the VND with random shaking to try to give the VND a chance to escape a local optima. In the implementation, it supports different implementations of VND and it has these parameters:  \textbf{shaking neighborhoods},  \textbf{local search neighborhoods},  \textbf{objective function},  \textbf{maximum number of iterations},  \textbf{vnd step function},  \textbf{vnd max iterations}. The only completely new parameter which was introduced was \textbf{shaking neighborhoods} and it is explained in the next paragraph.

\paragraph{Shaking neighborhoods:}
Similar to neighborhoods, shaking neighborhoods are possible solutions which can be achieved using specific rules from the current solution. The shaking neighborhoods are special as they always provide only one random solution from the counterpart normal neighborhood. These were the implemented ones:
\begin{itemize}
	\item \textbf{Swap neighborhood (n):} It returns a solution which can be found in the swap neighborhood. It also supports the creation of a n-swap neighborhood, which allows all solutions which can be achieved using n swaps from the current solution.
	\item \textbf{Insert neighborhood:} It returns a solution from the insert neighborhood.
	\item \textbf{Reverse neighborhood:} It returns a solution from the reverse neighborhood.
\end{itemize}

\subsection*{Performance}
The tests were ran on a Macbook Pro 16" M2 Pro.  The algorithm was limited to 15 min runtime on a single instance. All the test have been ran with the following parameters: 
\begin{itemize}
	\item \textbf{Max iterations:} 2
	\item \textbf{Neighborhood order:} Swap, Reverse, Insert
	\item \textbf{Neighborhood shake order:} Swap, Swap-3, Inesrt, Reverse
	\item \textbf{Step function:} First Improvement
	\item \textbf{VND max iterations:} 3
	\item \textbf{Times ran:} 5 for small and medium, 3 for medium\_large and large
\end{itemize}

\subsection*{Small}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
		\midrule
		\texttt{inst\_50\_4\_00002} & 0.104611 & 24933.6 & 23982.0 & 27000.0 & 1103.55 \\ 
		\texttt{inst\_50\_4\_00004} & 0.021516 & 7460.2  & 6942.0  & 8067.0  & 390.92 \\ 
		\texttt{inst\_50\_4\_00007} & 0.037690 & 2345.4  & 2099.0  & 2652.0  & 219.31 \\ 
		\texttt{inst\_50\_4\_00005} & 0.041543 & 3898.0  & 3691.0  & 4188.0  & 207.01 \\ 
		\texttt{inst\_50\_4\_00009} & 0.037616 & 1533.2  & 1385.0  & 1802.0  & 152.88 \\ 
		\texttt{inst\_50\_4\_00003} & 0.045658 & 13267.2 & 12821.0 & 13560.0 & 266.90 \\ 
		\texttt{inst\_50\_4\_00006} & 0.038624 & 3226.6  & 3102.0  & 3336.0  & 91.00  \\ 
		\texttt{inst\_50\_4\_00010} & 0.033737 & 1081.2  & 899.0   & 1624.0  & 276.06 \\ 
		\texttt{inst\_50\_4\_00001} & 0.088662 & 77435.4 & 74900.0 & 80848.0 & 2078.90 \\ 
		\texttt{inst\_50\_4\_00008} & 0.034032 & 1581.2  & 1470.0  & 1762.0  & 99.07  \\ 
		\midrule
		\textbf{Summary Statistics} & \textbf{0.0484} & \textbf{13676.2} & - & - & - \\
		\bottomrule
	\end{tabular}
	\label{tab:performance_metrics_small_gvns}
\end{table}


\subsection*{Medium}
\begin{table}[H]
	\centering 
	\begin{tabular}{lrrrrr} 
		\toprule 
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
		\midrule 
		\texttt{inst\_200\_20\_00010} & 3.9998 & 426375.8 & 405780.0 & 449650.0 & 14684.48 \\ 
		\texttt{inst\_200\_20\_00009} & 0.8330 & 525452.0 & 515265.0 & 537782.0 & 7186.38 \\ 
		\texttt{inst\_200\_20\_00008} & 0.6071 & 642463.2 & 627365.0 & 663653.0 & 11891.28 \\  
		\texttt{inst\_200\_20\_00007} & 1.4284 & 874448.0 & 862636.0 & 891027.0 & 12383.73 \\  
		\texttt{inst\_200\_20\_00006} & 7.3983 & 1140584.6 & 1106569.0 & 1185142.0 & 28084.81 \\  
		\texttt{inst\_200\_20\_00005} & 0.5746 & 1556662.8 & 1541167.0 & 1594146.0 & 19848.85 \\  
		\texttt{inst\_200\_20\_00004} & 0.9376 & 2408182.2 & 2344128.0 & 2474783.0 & 45656.43 \\  
		\texttt{inst\_200\_20\_00003} & 1.9283 & 4140673.8 & 4030008.0 & 4253200.0 & 71730.50 \\  
		\texttt{inst\_200\_20\_00002} & 18.5041 & 8127653.6 & 7955555.0 & 8250767.0 & 138759.84 \\  
		\texttt{inst\_200\_20\_00001} & 12.6312 & 22693077.6 & 22309294.0 & 22906959.0 & 219015.22 \\ 
		\midrule 
		\textbf{Summary Statistics} & \textbf{4.9745} & \textbf{6843733.10} & - & - \\ 
		\bottomrule
	\end{tabular}
	\label{tab:performance_metrics_medium_gvns}
\end{table}


\subsection*{Medium-Large}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} \\
		\midrule
		\texttt{inst\_500\_40\_00001} & 81.91235 & 40161294.00  & 40109112.00  & 40208298.00 &  40657.71\\
		\texttt{inst\_500\_40\_00010} & 20.28370 & 244675374.66 & 244449482.00 & 245069841.00 &  279909.67\\
		\texttt{inst\_500\_40\_00019} & 15.30449 & 528918152.33 & 526096773.00 & 530461681.00 & 1997962.66\\
		\texttt{inst\_500\_40\_00013} & 41.27252 & 330123938.0.00 & 328263464.00 & 331348436.00 & 1268323.96 \\
		\texttt{inst\_500\_40\_00007} & 21.765949 & 164770693.00 & 163821323.00 & 165299551.00  & 672761.60\\
		\texttt{inst\_500\_40\_00016} & 21.713235 & 432797031.67 & 431431993.00 & 434524182.00  & 1288086.91 \\
		\texttt{inst\_500\_40\_00004} & 18.120888 & 93151443.33  & 92486709.00  & 94022108.00  & 643515.35 \\
		\midrule
		\textbf{Summary Statistics} & \textbf{0.395245} & \textbf{265036374.55} & - & -  \\
		\bottomrule
	\end{tabular}
	\label{tab:medium_large_performance_metrics_gvns}
\end{table}


\subsection*{Large}
\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Item} & \textbf{Avg Time (s)} & \textbf{Avg Cost} & \textbf{Min Cost} & \textbf{Max Cost} & \textbf{Std Dev} \\
		\midrule
		\texttt{inst\_1000\_60\_00005} & 1.940377 & 1067764674.70  & 1060835463.00  & 1075136067.00  & 3443214.33  \\
		\texttt{inst\_1000\_60\_00002} & 5.258952 & 5339427349.17  & 5316206983.00  & 5358163297.00  & 9952612.22  \\
		\texttt{inst\_1000\_60\_00004} & 2.576052 & 1618919043.03  & 1604354503.00  & 1629522719.00  & 5881501.28  \\
		\texttt{inst\_1000\_60\_00001} & 9.653994 & 15145125818.07 & 15119309857.00 & 15174139010.00 & 15114903.03 \\
		\texttt{inst\_1000\_60\_00003} & 3.577870 & 2710183271.13  & 2698638355.00  & 2723048821.00  & 6434495.93  \\
		\texttt{inst\_1000\_60\_00007} & 1.234546 & 568833774.80   & 564743332.00   & 571513933.00   & 1777165.09  \\
		\texttt{inst\_1000\_60\_00006} & 1.506673 & 771255574.13   & 765180918.00   & 777979955.00   & 3043546.59  \\
		\texttt{inst\_1000\_60\_00008} & 1.053052 & 450177254.10   & 446090463.00   & 455253372.00   & 2137433.51  \\
		\texttt{inst\_1000\_60\_00009} & 0.886946 & 357376938.03   & 354133103.00   & 359544918.00   & 1668191.08  \\
		\texttt{inst\_1000\_60\_00010} & 0.773536 & 294319001.80   & 291894077.00   & 297714026.00   & 1198184.49  \\
		\midrule
		\textbf{Summary Statistics} & \textbf{} & \textbf{} & - & - & - \\
		\bottomrule
	\end{tabular}
	\label{tab:large_performance_metrics_gvns}
\end{table}





\end{document}
